const express = require("express");
const multer = require("multer");
const XLSX = require("xlsx");
const mongoose = require("mongoose");
const compression = require("compression");
const path = require("path");

const app = express();
const PORT = process.env.PORT || 3000;

app.use(compression());
app.use(express.static("public"));
app.use(express.static(path.join(__dirname, "public")));

// MongoDB connection
require("dotenv").config(); // ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©

mongoose
    .connect(process.env.MONGO_URI, {
        useNewUrlParser: true,
        useUnifiedTopology: true
    })
    .then(() => console.log("âœ… ØªÙ… Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª MongoDB"))
    .catch(err => console.error("âŒ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ MongoDB:", err));

// Schema without restrictions (dynamic)
const productSchema = new mongoose.Schema({}, { strict: false });
const Product = mongoose.model("Product", productSchema);

// Multer setup (in-memory)
const storage = multer.memoryStorage();
const upload = multer({ storage });

// ØªØ­Ø³ÙŠÙ†: Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù„Ù‰ Ø¯ÙØ¹Ø§Øª
async function insertInBatches(data, batchSize = 1000) {
    for (let i = 0; i < data.length; i += batchSize) {
        const batch = data.slice(i, i + batchSize);
        await Product.insertMany(batch);
        console.log(`âœ… Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø¯ÙØ¹Ø© ${i + 1} Ø¥Ù„Ù‰ ${i + batch.length}`);
    }
}

// Ù†Ù‚Ø·Ø© Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù
app.post("/upload", upload.single("file"), async (req, res) => {
    try {
        if (!req.file) {
            return res.status(400).json({ error: "âŒ Ù„Ù… ÙŠØªÙ… Ø±ÙØ¹ Ø£ÙŠ Ù…Ù„Ù" });
        }

        const workbook = XLSX.read(req.file.buffer, { type: "buffer" });
        const sheetName = workbook.SheetNames[0];
        console.log("Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£ÙˆØ±Ø§Ù‚ ÙÙŠ Ø§Ù„Ù…Ù„Ù:", workbook.SheetNames);

        const jsonData = XLSX.utils.sheet_to_json(workbook.Sheets[sheetName]);
        console.log(`âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ ${jsonData.length} Ø³Ø¬Ù„ Ù…Ù† Ø§Ù„Ù…Ù„Ù`);

        if (!jsonData.length) {
            return res
                .status(400)
                .json({ error: "âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ù„Ù" });
        }

        await Product.deleteMany({});
        console.log("âœ… ØªÙ… Ø­Ø°Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©");

        await insertInBatches(jsonData);

        res.json({
            message: "âœ… ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù ÙˆØ­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­",
            count: jsonData.length
        });
    } catch (err) {
        console.error("âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©:", err);
        res.status(500).json({
            error: "âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù",
            details: err.message
        });
    }
});

// Ù†Ù‚Ø·Ø© Ø¨Ø­Ø« Ø¨Ø³ÙŠØ·Ø©
app.get("/search", async (req, res) => {
    const { q } = req.query;
    if (!q) return res.status(400).send("ÙŠØ±Ø¬Ù‰ Ø¥Ø±Ø³Ø§Ù„ ÙƒÙ„Ù…Ø© Ù„Ù„Ø¨Ø­Ø«");

    const searchRegex = new RegExp(q, "i");

    const results = await Product.find({
        $or: [{ LIBELLE: searchRegex }, { ANPF: q }, { GENCOD_P: q }]
    }).limit(10);

    res.json(results);
});

app.listen(PORT, () => {
    console.log(`ğŸš€ Server is running on http://localhost:${PORT}`);
});
